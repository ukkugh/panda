{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from urllib.request import urlopen\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_format(d):\n",
    "    d = str(d).replace('-', '.')\n",
    "    \n",
    "    yyyy = int(d.split('.')[0]) \n",
    "    mm = int(d.split('.')[1])\n",
    "    dd = int(d.split('.')[2])\n",
    "\n",
    "    this_date= dt.date(yyyy, mm, dd)\n",
    "    return this_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_index_naver(index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "    #index_cd = 'KOSPI' 'KOSDAQ' 'KPI200''FUT' \n",
    "    \n",
    "    if start_date:   # start_date가 있으면\n",
    "        start_date = date_format(start_date)   # date 포맷으로 변환\n",
    "    else:    # 없으면\n",
    "        start_date = dt.date.today()   # 오늘 날짜를 지정\n",
    "    if end_date:   \n",
    "        end_date = date_format(end_date)   \n",
    "    else:   \n",
    "        end_date = dt.date.today()  \n",
    "        \n",
    "        \n",
    "    naver_index = 'http://finance.naver.com/sise/sise_index_day.nhn?code=' + index_cd + '&page=' + str(page_n)\n",
    "    \n",
    "    source = urlopen(naver_index).read()         # 지정한 페이지에서 코드 읽기\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "    \n",
    "    dates = source.find_all('td', class_='date')        # <td class=\"date\">태그에서 날짜 수집   \n",
    "    prices = source.find_all('td', class_='number_1')   # <td class=\"number_1\">태그에서 지수 수집\n",
    "    \n",
    "    # 아래에서 this_data는 page_n = 1에서 나온 date를 사용하기 때문에 오늘 날짜 포함 6개의 이전 날자들을 포함(최신)\n",
    "    # 이 후로 historical_index_naver함수가 page_n값을 증가(다음 페이지) 시키면서 점점 날짜(this_date)는 과거로 가게 되고\n",
    "    # this_data이 start_date을 지나 더 과거로 가게 되는 순간 지금까지 저장된 dic값을 리턴하고 종료\n",
    "    \n",
    "    # 특정 시점이후 데이터가 없는 경우(선물의 경우)가 발생하면 naver_index에 의해 urlopen이 fail이 나거나\n",
    "    # 문제가 없더라도 source내에는 우리가 원하는 data가 들어 있지 않을 것이다. 그런 상태에서 dates와 prices를\n",
    "    # 추출하는 것이 의미 없기는 하겠지만 일단 추출한다 해도 dates의 값은 Null로 td나 class관련해서 아무 것도 없게 될 것이고\n",
    "    # 그것은 len(dates)가 0이 되어 딕션너리에 아무런 저장을 하지 않겠지만 page_n == last_page가 될 때까지 \n",
    "    # 쓸데 없이 반복 호출 되는 비효율적인면을 개선할 필요가 있다. (위쪽에 체크 루틴을 넣어 주면 좋을 듯)\n",
    "    for n in range(len(dates)):\n",
    "    \n",
    "        if dates[n].text.split('.')[0].isdigit():\n",
    "            \n",
    "            # 날짜 처리\n",
    "            this_date = dates[n].text\n",
    "            this_date= date_format(this_date)\n",
    "            \n",
    "            if this_date <= end_date and this_date >= start_date:   \n",
    "            # start_date와 end_date 사이에서 데이터 저장\n",
    "                # 종가 처리\n",
    "                this_close = prices[n*4].text   # prices 중 종가지수인 0,4,8,...번째 데이터 추출\n",
    "                this_close = this_close.replace(',', '')\n",
    "                this_close = float(this_close)\n",
    "\n",
    "                # 딕셔너리에 저장\n",
    "                historical_prices[this_date] = this_close\n",
    "                \n",
    "            elif this_date < start_date:   \n",
    "            # start_date 이전이면 함수 종료 (설정한 시작점 보다 더 과거의 data는 더 이상 처리 하지 않는다)\n",
    "                return historical_prices              \n",
    "            \n",
    "    # 페이지 네비게이션 : 매번 재귀호출 때마다 반복 실행 시킬 필요 없을 것 같은데.. 구조 잘 못 짠것 같음\n",
    "    if last_page == 0:\n",
    "        last_page = source.find('td', class_='pgRR').find('a')['href']\n",
    "        # 마지막페이지 주소 추출\n",
    "        last_page = last_page.split('&')[1]   # & 뒤의 page=506 부분 추출\n",
    "        last_page = last_page.split('=')[1]   # = 뒤의 페이지번호만 추출\n",
    "        last_page = int(last_page)   # 숫자형 변수로 변환\n",
    "        \n",
    "    # 다음 페이지 호출\n",
    "    if page_n < last_page:   \n",
    "        page_n = page_n + 1   \n",
    "        historical_index_naver(index_cd, start_date, end_date, page_n, last_page)   \n",
    "    \n",
    "    # 이것이 호출 된다는 것은 page_n == last_page 인 경우이다.\n",
    "    return historical_prices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historical_global_daum(index_cd, start_date='', end_date='', page_n=1, last_page=0):\n",
    "    \n",
    "    #index_cd = 'KOSPI' 'KOSDAQ' 'KPI200''FUT' \n",
    "    if start_date:   # start_date가 있으면\n",
    "        start_date = date_format(start_date)   # date 포맷으로 변환\n",
    "    else:    # 없으면\n",
    "        start_date = dt.date.today()   # 오늘 날짜를 지정\n",
    "    if end_date:  \n",
    "        end_date = date_format(end_date)   \n",
    "    else:   \n",
    "        end_date = dt.date.today()  \n",
    "    \n",
    "    url = 'http://finance.daum.net/global/index_daily.daum?type=default&ric=/.' + index_cd + '&page=' + str(page_n)\n",
    "\n",
    "    source = urlopen(url).read()\n",
    "    source = bs4.BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    dates = source.find_all('td', class_='datetime')   # <td class=\"datetime\">태그에서 날짜 수집\n",
    "    prices = source.find_all('td', class_='num')   # <td class=\"num\">태그에서 날짜 수집\n",
    "\n",
    "    rows_in_page = len(dates)\n",
    "\n",
    "    # 데이터가 없는 경우는 바로 dic값 가지고 리턴\n",
    "    # 일반적으로 10일 것이고 마지막 페이지만 행이 10 이하일 가능성이 높다.\n",
    "    if len(dates) > 0:\n",
    "\n",
    "        for n in range(rows_in_page):\n",
    "\n",
    "            # 날짜 처리\n",
    "            this_date = dates[n].text\n",
    "            this_date= date_format(this_date)\n",
    "\n",
    "            if this_date <= end_date and this_date >= start_date:   \n",
    "            # start_date와 end_date 사이에서 데이터 저장\n",
    "                # 종가 처리, 0, 3, 6, 9와 같은 순서로 종가를 가진 index이며 실제 내용에 종가 외에\n",
    "                # 천단위 외에 다양한 \\t, \\n과 같은 데이터들이 있으므로 그것들을 지워준다.\n",
    "                this_close = prices[n*3].text\n",
    "                this_close = this_close.replace(' ', '')\n",
    "                this_close = this_close.replace('\\t', '')\n",
    "                this_close = this_close.replace('\\n', '')\n",
    "                this_close = this_close.replace(',', '')\n",
    "                this_close = float(this_close)\n",
    "\n",
    "                # 딕셔너리에 저장\n",
    "                historical_prices[this_date] = this_close\n",
    "                \n",
    "            elif this_date < start_date:   \n",
    "            # start_date 이전이면 함수 종료\n",
    "                return historical_prices                         \n",
    "        \n",
    "        # 페이지 네비게이션\n",
    "        # 다음은 페이지당 행이 10개가 기본임 그러므로 10 인 경우는 다음번 페이지로 진행이 가능함.\n",
    "        # 10이 아닌 경우는 마지막 페이지일 것이므로 return한다.\n",
    "        if rows_in_page == 10:\n",
    "            page_n = int(page_n)\n",
    "            page_n = page_n + 1\n",
    "            \n",
    "            historical_global_daum(index_cd, start_date, end_date, page_n, last_page)\n",
    "            \n",
    "    return historical_prices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2018, 8, 1): 2307.07,\n",
       " datetime.date(2018, 7, 31): 2295.26,\n",
       " datetime.date(2018, 7, 30): 2293.51,\n",
       " datetime.date(2018, 7, 27): 2294.99,\n",
       " datetime.date(2018, 7, 26): 2289.06,\n",
       " datetime.date(2018, 7, 25): 2273.03,\n",
       " datetime.date(2018, 7, 24): 2280.2,\n",
       " datetime.date(2018, 7, 23): 2269.31,\n",
       " datetime.date(2018, 7, 20): 2289.19,\n",
       " datetime.date(2018, 7, 19): 2282.29,\n",
       " datetime.date(2018, 7, 18): 2290.11,\n",
       " datetime.date(2018, 7, 17): 2297.92,\n",
       " datetime.date(2018, 7, 16): 2301.99,\n",
       " datetime.date(2018, 7, 13): 2310.9,\n",
       " datetime.date(2018, 7, 12): 2285.06,\n",
       " datetime.date(2018, 7, 11): 2280.62,\n",
       " datetime.date(2018, 7, 10): 2294.16,\n",
       " datetime.date(2018, 7, 9): 2285.8,\n",
       " datetime.date(2018, 7, 6): 2272.87,\n",
       " datetime.date(2018, 7, 5): 2257.55,\n",
       " datetime.date(2018, 7, 4): 2265.46,\n",
       " datetime.date(2018, 7, 3): 2272.76,\n",
       " datetime.date(2018, 7, 2): 2271.54}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index_cd = 'KOSPI' 'KOSDAQ' 'KPI200''FUT' \n",
    "historical_prices = dict()\n",
    "#historical_index_naver(index_cd, '2018-1-1', '2018-7-1')\n",
    "my_own_dic = historical_index_naver('KOSPI', '2018-7-1', '2018-8-1')\n",
    "my_own_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2018, 8, 8): 2744.07,\n",
       " datetime.date(2018, 8, 7): 2779.37,\n",
       " datetime.date(2018, 8, 6): 2705.16,\n",
       " datetime.date(2018, 8, 3): 2740.44,\n",
       " datetime.date(2018, 8, 2): 2768.02,\n",
       " datetime.date(2018, 8, 1): 2824.53,\n",
       " datetime.date(2018, 7, 31): 2876.4,\n",
       " datetime.date(2018, 7, 30): 2869.05,\n",
       " datetime.date(2018, 7, 27): 2873.59,\n",
       " datetime.date(2018, 7, 26): 2882.23,\n",
       " datetime.date(2018, 7, 25): 2903.65,\n",
       " datetime.date(2018, 7, 24): 2905.56,\n",
       " datetime.date(2018, 7, 23): 2859.54,\n",
       " datetime.date(2018, 7, 20): 2829.27,\n",
       " datetime.date(2018, 7, 19): 2772.55,\n",
       " datetime.date(2018, 7, 18): 2787.26,\n",
       " datetime.date(2018, 7, 17): 2798.13,\n",
       " datetime.date(2018, 7, 16): 2814.04,\n",
       " datetime.date(2018, 7, 13): 2831.18,\n",
       " datetime.date(2018, 7, 12): 2837.66,\n",
       " datetime.date(2018, 7, 11): 2777.77,\n",
       " datetime.date(2018, 7, 10): 2827.63,\n",
       " datetime.date(2018, 7, 9): 2815.11,\n",
       " datetime.date(2018, 7, 6): 2747.23,\n",
       " datetime.date(2018, 7, 5): 2733.88,\n",
       " datetime.date(2018, 7, 4): 2759.13,\n",
       " datetime.date(2018, 7, 3): 2786.89,\n",
       " datetime.date(2018, 7, 2): 2775.56,\n",
       " datetime.date(2018, 6, 29): 2847.42,\n",
       " datetime.date(2018, 6, 28): 2786.9,\n",
       " datetime.date(2018, 6, 27): 2813.18,\n",
       " datetime.date(2018, 6, 26): 2844.51,\n",
       " datetime.date(2018, 6, 25): 2859.34,\n",
       " datetime.date(2018, 6, 22): 2889.76,\n",
       " datetime.date(2018, 6, 21): 2875.81,\n",
       " datetime.date(2018, 6, 20): 2915.73,\n",
       " datetime.date(2018, 6, 19): 2907.82,\n",
       " datetime.date(2018, 6, 15): 3021.9,\n",
       " datetime.date(2018, 6, 14): 3044.16,\n",
       " datetime.date(2018, 6, 13): 3049.8,\n",
       " datetime.date(2018, 6, 12): 3079.8,\n",
       " datetime.date(2018, 6, 11): 3052.78,\n",
       " datetime.date(2018, 6, 8): 3067.15,\n",
       " datetime.date(2018, 6, 7): 3109.5,\n",
       " datetime.date(2018, 6, 6): 3115.18,\n",
       " datetime.date(2018, 6, 5): 3114.21,\n",
       " datetime.date(2018, 6, 4): 3091.19,\n",
       " datetime.date(2018, 6, 1): 3075.14,\n",
       " datetime.date(2018, 5, 31): 3095.47,\n",
       " datetime.date(2018, 5, 30): 3041.44,\n",
       " datetime.date(2018, 5, 29): 3120.46,\n",
       " datetime.date(2018, 5, 28): 3135.08,\n",
       " datetime.date(2018, 5, 25): 3141.3,\n",
       " datetime.date(2018, 5, 24): 3154.65,\n",
       " datetime.date(2018, 5, 23): 3168.96,\n",
       " datetime.date(2018, 5, 22): 3214.35,\n",
       " datetime.date(2018, 5, 21): 3213.84,\n",
       " datetime.date(2018, 5, 18): 3193.3,\n",
       " datetime.date(2018, 5, 17): 3154.28,\n",
       " datetime.date(2018, 5, 16): 3169.57,\n",
       " datetime.date(2018, 5, 15): 3192.12,\n",
       " datetime.date(2018, 5, 14): 3174.03,\n",
       " datetime.date(2018, 5, 11): 3163.26,\n",
       " datetime.date(2018, 5, 10): 3174.41,\n",
       " datetime.date(2018, 5, 9): 3159.15,\n",
       " datetime.date(2018, 5, 8): 3161.5,\n",
       " datetime.date(2018, 5, 7): 3136.64,\n",
       " datetime.date(2018, 5, 4): 3091.03,\n",
       " datetime.date(2018, 5, 3): 3100.86,\n",
       " datetime.date(2018, 5, 2): 3081.18,\n",
       " datetime.date(2018, 4, 27): 3082.23,\n",
       " datetime.date(2018, 4, 26): 3075.03,\n",
       " datetime.date(2018, 4, 25): 3117.97,\n",
       " datetime.date(2018, 4, 24): 3128.93,\n",
       " datetime.date(2018, 4, 23): 3068.01,\n",
       " datetime.date(2018, 4, 20): 3071.54,\n",
       " datetime.date(2018, 4, 19): 3117.38,\n",
       " datetime.date(2018, 4, 18): 3091.4,\n",
       " datetime.date(2018, 4, 17): 3066.8,\n",
       " datetime.date(2018, 4, 16): 3110.65,\n",
       " datetime.date(2018, 4, 13): 3159.05,\n",
       " datetime.date(2018, 4, 12): 3180.16,\n",
       " datetime.date(2018, 4, 11): 3208.08,\n",
       " datetime.date(2018, 4, 10): 3190.32,\n",
       " datetime.date(2018, 4, 9): 3138.29,\n",
       " datetime.date(2018, 4, 4): 3131.11,\n",
       " datetime.date(2018, 4, 3): 3136.63,\n",
       " datetime.date(2018, 4, 2): 3163.18,\n",
       " datetime.date(2018, 3, 30): 3168.9,\n",
       " datetime.date(2018, 3, 29): 3160.53,\n",
       " datetime.date(2018, 3, 28): 3122.29,\n",
       " datetime.date(2018, 3, 27): 3166.65,\n",
       " datetime.date(2018, 3, 26): 3133.72,\n",
       " datetime.date(2018, 3, 23): 3152.76,\n",
       " datetime.date(2018, 3, 22): 3263.48,\n",
       " datetime.date(2018, 3, 21): 3280.95,\n",
       " datetime.date(2018, 3, 20): 3290.64,\n",
       " datetime.date(2018, 3, 19): 3279.25,\n",
       " datetime.date(2018, 3, 16): 3269.88,\n",
       " datetime.date(2018, 3, 15): 3291.11,\n",
       " datetime.date(2018, 3, 14): 3291.38,\n",
       " datetime.date(2018, 3, 13): 3310.24,\n",
       " datetime.date(2018, 3, 12): 3326.7,\n",
       " datetime.date(2018, 3, 9): 3307.17,\n",
       " datetime.date(2018, 3, 8): 3288.41,\n",
       " datetime.date(2018, 3, 7): 3271.67,\n",
       " datetime.date(2018, 3, 6): 3289.64,\n",
       " datetime.date(2018, 3, 5): 3256.93,\n",
       " datetime.date(2018, 3, 2): 3254.53,\n",
       " datetime.date(2018, 3, 1): 3273.75,\n",
       " datetime.date(2018, 2, 28): 3259.41,\n",
       " datetime.date(2018, 2, 27): 3292.07,\n",
       " datetime.date(2018, 2, 26): 3329.57,\n",
       " datetime.date(2018, 2, 23): 3289.02,\n",
       " datetime.date(2018, 2, 22): 3268.56,\n",
       " datetime.date(2018, 2, 14): 3199.16,\n",
       " datetime.date(2018, 2, 13): 3184.96,\n",
       " datetime.date(2018, 2, 12): 3154.13,\n",
       " datetime.date(2018, 2, 9): 3129.85,\n",
       " datetime.date(2018, 2, 8): 3262.05,\n",
       " datetime.date(2018, 2, 7): 3309.26,\n",
       " datetime.date(2018, 2, 6): 3370.65,\n",
       " datetime.date(2018, 2, 5): 3487.5,\n",
       " datetime.date(2018, 2, 2): 3462.08,\n",
       " datetime.date(2018, 2, 1): 3446.98,\n",
       " datetime.date(2018, 1, 31): 3480.83,\n",
       " datetime.date(2018, 1, 30): 3488.01,\n",
       " datetime.date(2018, 1, 29): 3523.0,\n",
       " datetime.date(2018, 1, 26): 3558.13,\n",
       " datetime.date(2018, 1, 25): 3548.31,\n",
       " datetime.date(2018, 1, 24): 3559.47,\n",
       " datetime.date(2018, 1, 23): 3546.5,\n",
       " datetime.date(2018, 1, 22): 3501.36,\n",
       " datetime.date(2018, 1, 19): 3487.86,\n",
       " datetime.date(2018, 1, 18): 3474.75,\n",
       " datetime.date(2018, 1, 17): 3444.67,\n",
       " datetime.date(2018, 1, 16): 3436.59,\n",
       " datetime.date(2018, 1, 15): 3410.49,\n",
       " datetime.date(2018, 1, 12): 3428.94,\n",
       " datetime.date(2018, 1, 11): 3425.34,\n",
       " datetime.date(2018, 1, 10): 3421.83,\n",
       " datetime.date(2018, 1, 9): 3413.9,\n",
       " datetime.date(2018, 1, 8): 3409.48,\n",
       " datetime.date(2018, 1, 5): 3391.75,\n",
       " datetime.date(2018, 1, 4): 3385.71,\n",
       " datetime.date(2018, 1, 3): 3369.11,\n",
       " datetime.date(2018, 1, 2): 3348.33}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#index_cd = 'GSPC' = S&P500 'IXIC'=NASDAQ 'DJI'= DOW\n",
    "#index_cd = 'N225' = 니케이225 'SSEC'=중국상해종합 'HSI'=홍콩항셍\n",
    "historical_prices = dict()\n",
    "#historical_index_naver(index_cd, '2018-1-1', '2018-7-1')\n",
    "sp500 = historical_global_daum('SSEC', '2018-1-1', '2018-8-8')\n",
    "sp500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
